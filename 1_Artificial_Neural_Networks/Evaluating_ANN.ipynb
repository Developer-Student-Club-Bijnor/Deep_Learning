{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluating_ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNffMwN/grwiMJhVWemgslv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/its-Kumar/Deep_Learning/blob/master/its-Kumar/1_Artificial_Neural_Networks/Evaluating_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2uzescSxxPC",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz2e60mymOpW",
        "colab_type": "text"
      },
      "source": [
        "## Part 1 - Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPsyo8sdnJuQ",
        "colab_type": "text"
      },
      "source": [
        "### Importing the libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlnfAJ6nmOpY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "77cdc52c-3e73-4610-ffdb-3cb30e4c9275"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiFHxj8Nna-l",
        "colab_type": "text"
      },
      "source": [
        "### Importing the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myMDnN3BmOpg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "59d18038-bb58-470f-fade-65790d487924"
      },
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "dataset"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9996</td>\n",
              "      <td>15606229</td>\n",
              "      <td>Obijiaku</td>\n",
              "      <td>771</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9997</td>\n",
              "      <td>15569892</td>\n",
              "      <td>Johnstone</td>\n",
              "      <td>516</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9998</td>\n",
              "      <td>15584532</td>\n",
              "      <td>Liu</td>\n",
              "      <td>709</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9999</td>\n",
              "      <td>15682355</td>\n",
              "      <td>Sabbatini</td>\n",
              "      <td>772</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>10000</td>\n",
              "      <td>15628319</td>\n",
              "      <td>Walker</td>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      RowNumber  CustomerId    Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0             1    15634602   Hargrave  ...               1       101348.88      1\n",
              "1             2    15647311       Hill  ...               1       112542.58      0\n",
              "2             3    15619304       Onio  ...               0       113931.57      1\n",
              "3             4    15701354       Boni  ...               0        93826.63      0\n",
              "4             5    15737888   Mitchell  ...               1        79084.10      0\n",
              "...         ...         ...        ...  ...             ...             ...    ...\n",
              "9995       9996    15606229   Obijiaku  ...               0        96270.64      0\n",
              "9996       9997    15569892  Johnstone  ...               1       101699.77      0\n",
              "9997       9998    15584532        Liu  ...               1        42085.58      1\n",
              "9998       9999    15682355  Sabbatini  ...               0        92888.52      1\n",
              "9999      10000    15628319     Walker  ...               0        38190.78      0\n",
              "\n",
              "[10000 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN4Ha5lvniif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "20ec4914-2e5a-4ef6-c22d-e42f02a0d61f"
      },
      "source": [
        "X = dataset.iloc[:, 3:-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "X"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
              "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
              "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
              "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
              "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utqv9mddmOpp",
        "colab_type": "text"
      },
      "source": [
        "### Encoding categorical data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJCOJ7ykmOp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X[:, 2] = le.fit_transform(X[:, 2])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fxp3xulmOpr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "814e213c-a2c7-40fe-92a1-37af993a5d3f"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "ct =  ColumnTransformer([('encoder', OneHotEncoder(), [1])],\n",
        "                        remainder='passthrough')\n",
        "X = ct.fit_transform(X)\n",
        "X[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.0, 0.0, 0.0, 619, 0, 42, 2, 0.0, 1, 1, 1, 101348.88],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "admtiTOvos9Z",
        "colab_type": "text"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laY-2mDUmOqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stmQWhpqo4xO",
        "colab_type": "text"
      },
      "source": [
        "### Feature Scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz5s-9PcmOqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XLt2N8bycZA",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating, improving and tuning the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jovX0jFJyi8i",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating the ANN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TV5pER9yfTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_classifier():\n",
        "    classifier = keras.models.Sequential()\n",
        "    classifier.add(keras.layers.Dense(units=8, activation='relu'))\n",
        "    classifier.add(keras.layers.Dense(units=8, activation='relu'))\n",
        "    classifier.add(keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "    classifier.compile(optimizer='adam', loss='binary_crossentropy',\n",
        "                       metrics = ['accuracy'])\n",
        "    return classifier"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sUhOdYRzUrB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a183556-e631-42b0-a134-ef4309dd3efd"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "classifier = KerasClassifier(build_fn=build_classifier,\n",
        "                             batch_size=25,\n",
        "                             nb_epoch=100)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D22F_LMQP2fa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3c705f21-8bf8-49dc-f4d1-b3eae4507d2f"
      },
      "source": [
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5647 - accuracy: 0.7211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f59448f64a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WIE0iX-Pb1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_test) > 0.5"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1OZm5AAPBwp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aa624c33-5d56-4f7f-aa64-040727f5e48a"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1565,   30],\n",
              "       [ 375,   30]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-29zPpd-zeGi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "bd33f7d5-7a2d-4ad6-c1d1-0d893a60d241"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator=classifier,\n",
        "                             X=X_train,\n",
        "                             y=y_train,\n",
        "                             cv=10)\n",
        "print(accuracies.mean())\n",
        "print(accuracies.std())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "288/288 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.7754\n",
            "32/32 [==============================] - 0s 941us/step - loss: 0.4633 - accuracy: 0.7825\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.7797\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.7887\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5419 - accuracy: 0.7956\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.8000\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.7708\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5028 - accuracy: 0.7837\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5615 - accuracy: 0.7525\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.8163\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.6544\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.8087\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.7224 - accuracy: 0.5669\n",
            "32/32 [==============================] - 0s 981us/step - loss: 0.5187 - accuracy: 0.7887\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.7961\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.7937\n",
            "288/288 [==============================] - 0s 997us/step - loss: 0.5526 - accuracy: 0.7399\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.8025\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.7940\n",
            "32/32 [==============================] - 0s 966us/step - loss: 0.4656 - accuracy: 0.7950\n",
            "0.7960000038146973\n",
            "0.010365206830375636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJSwjqN9z2R1",
        "colab_type": "text"
      },
      "source": [
        "### improving the ANN\n",
        "\n",
        "dropout regularization to reduce overfitting if needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CUCMf3Qzxo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuSK-C8dz_MB",
        "colab_type": "text"
      },
      "source": [
        "### Tuning the ANN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNcOEv1S0Aqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_classifier(optimizer):\n",
        "    classifier = keras.models.Sequential()\n",
        "    classifier.add(keras.layers.Dense(units=8, activation='relu'))\n",
        "    classifier.add(keras.layers.Dense(units=8, activation='relu'))\n",
        "    classifier.add(keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "    classifier.compile(optimizer=optimizer, loss='binary_crossentropy',\n",
        "                       metrics = ['accuracy'])\n",
        "    return classifier"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tcvf1jiP0TM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "classifier = KerasClassifier(build_fn=build_classifier)\n",
        "parameters = {\n",
        "    'batch_size': [5, 10, 25, 32],\n",
        "    'nb_epoch': [10, 50, 100, 300, 500],\n",
        "    'optimizer': ['adam', 'rmsprop']\n",
        "    }\n",
        "grid_search = GridSearchCV(estimator=classifier,\n",
        "                           param_grid=parameters,\n",
        "                           scoring='accuracy',\n",
        "                           cv=10)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzAy-XAT0ljZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ab1a8f2-d16d-4949-f7f4-d4278113b0bf"
      },
      "source": [
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "best_param = grid_search.best_params_\n",
        "best_acc = grid_search.best_score_"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4705 - accuracy: 0.7971\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4561 - accuracy: 0.8094\n",
            "1440/1440 [==============================] - 1s 995us/step - loss: 0.4690 - accuracy: 0.7986\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4791 - accuracy: 0.7985\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.5309 - accuracy: 0.7543\n",
            "1440/1440 [==============================] - 1s 989us/step - loss: 0.4663 - accuracy: 0.7829\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4748 - accuracy: 0.7911\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4860 - accuracy: 0.7962\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4843 - accuracy: 0.7758\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4778 - accuracy: 0.7969\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4848 - accuracy: 0.7917\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4872 - accuracy: 0.7856\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.5272 - accuracy: 0.7582\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4785 - accuracy: 0.7926\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4835 - accuracy: 0.7936\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4677 - accuracy: 0.7942\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4734 - accuracy: 0.7969\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4708 - accuracy: 0.7924\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4772 - accuracy: 0.7914\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4575 - accuracy: 0.7999\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4922 - accuracy: 0.7869\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4839 - accuracy: 0.7979\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4774 - accuracy: 0.7958\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4941 - accuracy: 0.7956\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4897 - accuracy: 0.7937\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4882 - accuracy: 0.7994\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4883 - accuracy: 0.7890\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4701 - accuracy: 0.7962\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4908 - accuracy: 0.7944\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4941 - accuracy: 0.7717\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.5055 - accuracy: 0.7708\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4666 - accuracy: 0.7906\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4854 - accuracy: 0.7943\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4702 - accuracy: 0.7871\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.5017 - accuracy: 0.7749\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4927 - accuracy: 0.7690\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4783 - accuracy: 0.7788\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4842 - accuracy: 0.7907\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4788 - accuracy: 0.7986\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.5076 - accuracy: 0.7731\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4778 - accuracy: 0.7926\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4547 - accuracy: 0.7996\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4954 - accuracy: 0.7779\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.5097 - accuracy: 0.7657\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4969 - accuracy: 0.7825\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4908 - accuracy: 0.7965\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.5174 - accuracy: 0.7588\n",
            "1440/1440 [==============================] - 1s 998us/step - loss: 0.4760 - accuracy: 0.7999\n",
            "1440/1440 [==============================] - 1s 996us/step - loss: 0.4607 - accuracy: 0.8014\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4764 - accuracy: 0.7960\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4902 - accuracy: 0.7733\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.5212 - accuracy: 0.7551\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4838 - accuracy: 0.7956\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.5176 - accuracy: 0.7650\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4793 - accuracy: 0.7861\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4820 - accuracy: 0.7786\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4974 - accuracy: 0.7686\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4951 - accuracy: 0.7668\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4692 - accuracy: 0.8033\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4935 - accuracy: 0.7883\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4917 - accuracy: 0.7971\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.5207 - accuracy: 0.7590\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4960 - accuracy: 0.7961\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4902 - accuracy: 0.7801\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4898 - accuracy: 0.7718\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.5044 - accuracy: 0.7765\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.5097 - accuracy: 0.7890\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4817 - accuracy: 0.7881\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.5179 - accuracy: 0.7751\n",
            "1440/1440 [==============================] - 1s 996us/step - loss: 0.4750 - accuracy: 0.7922\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4980 - accuracy: 0.7839\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4744 - accuracy: 0.7937\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.5012 - accuracy: 0.7839\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4656 - accuracy: 0.7975\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4895 - accuracy: 0.7876\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4920 - accuracy: 0.7965\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.5018 - accuracy: 0.7801\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4825 - accuracy: 0.7876\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4846 - accuracy: 0.7856\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4951 - accuracy: 0.7939\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4760 - accuracy: 0.7957\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4778 - accuracy: 0.8000\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.5004 - accuracy: 0.7726\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.5113 - accuracy: 0.7679\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4837 - accuracy: 0.7865\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4771 - accuracy: 0.7892\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4815 - accuracy: 0.7915\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4800 - accuracy: 0.7917\n",
            "1440/1440 [==============================] - 1s 1ms/step - loss: 0.4725 - accuracy: 0.7946\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4792 - accuracy: 0.7969\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4755 - accuracy: 0.8007\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4736 - accuracy: 0.8015\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4784 - accuracy: 0.7897\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4762 - accuracy: 0.7958\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.5009 - accuracy: 0.7725\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4894 - accuracy: 0.7915\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.5063 - accuracy: 0.7624\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4858 - accuracy: 0.7928\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4908 - accuracy: 0.7903\n",
            "1440/1440 [==============================] - 2s 1ms/step - loss: 0.5006 - accuracy: 0.7958\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5693 - accuracy: 0.7083\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5053 - accuracy: 0.7771\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5104 - accuracy: 0.7615\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4729 - accuracy: 0.7968\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5021 - accuracy: 0.7933\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4953 - accuracy: 0.7788\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5201 - accuracy: 0.7672\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5869 - accuracy: 0.7157\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4966 - accuracy: 0.7862\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5629 - accuracy: 0.7192\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4847 - accuracy: 0.7990\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4894 - accuracy: 0.7939\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7706\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4857 - accuracy: 0.7893\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5626 - accuracy: 0.7349\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5020 - accuracy: 0.7944\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5173 - accuracy: 0.7869\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5057 - accuracy: 0.7962\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4969 - accuracy: 0.7826\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5405 - accuracy: 0.7371\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5004 - accuracy: 0.7854\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5523 - accuracy: 0.7250\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5584 - accuracy: 0.7256\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4962 - accuracy: 0.7882\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5311 - accuracy: 0.7375\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4964 - accuracy: 0.7929\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4941 - accuracy: 0.7868\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5013 - accuracy: 0.7939\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4801 - accuracy: 0.7956\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5218 - accuracy: 0.7325\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5188 - accuracy: 0.7732\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5157 - accuracy: 0.7796\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4867 - accuracy: 0.8004\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5332 - accuracy: 0.7381\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4960 - accuracy: 0.7901\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5005 - accuracy: 0.7589\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5212 - accuracy: 0.7815\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5095 - accuracy: 0.7704\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5234 - accuracy: 0.7521\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5095 - accuracy: 0.7790\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5053 - accuracy: 0.7789\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4949 - accuracy: 0.7704\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5398 - accuracy: 0.7457\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5497 - accuracy: 0.7265\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4978 - accuracy: 0.7853\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4769 - accuracy: 0.7944\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4815 - accuracy: 0.7921\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5088 - accuracy: 0.7751\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4762 - accuracy: 0.7949\n",
            "720/720 [==============================] - 1s 988us/step - loss: 0.5136 - accuracy: 0.7776\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5724 - accuracy: 0.7201\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5185 - accuracy: 0.7508\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4954 - accuracy: 0.7918\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4798 - accuracy: 0.7976\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5550 - accuracy: 0.7179\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4994 - accuracy: 0.7767\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5538 - accuracy: 0.7424\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5717 - accuracy: 0.7231\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4996 - accuracy: 0.7811\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4779 - accuracy: 0.7867\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7297\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5691 - accuracy: 0.7212\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5053 - accuracy: 0.7731\n",
            "720/720 [==============================] - 1s 996us/step - loss: 0.4928 - accuracy: 0.7965\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5347 - accuracy: 0.7707\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5060 - accuracy: 0.7776\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4828 - accuracy: 0.7961\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5100 - accuracy: 0.7915\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5222 - accuracy: 0.7460\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4918 - accuracy: 0.7815\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4899 - accuracy: 0.7971\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4868 - accuracy: 0.7975\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5049 - accuracy: 0.7847\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4932 - accuracy: 0.7865\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4938 - accuracy: 0.7793\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4947 - accuracy: 0.7942\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4869 - accuracy: 0.7842\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4938 - accuracy: 0.7817\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5299 - accuracy: 0.7428\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4926 - accuracy: 0.7957\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5317 - accuracy: 0.7467\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4988 - accuracy: 0.7738\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5261 - accuracy: 0.7918\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5403 - accuracy: 0.7685\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7511\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5175 - accuracy: 0.7667\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5109 - accuracy: 0.7754\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4834 - accuracy: 0.7926\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5084 - accuracy: 0.7757\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4963 - accuracy: 0.7875\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4902 - accuracy: 0.7981\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4978 - accuracy: 0.7824\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5221 - accuracy: 0.7794\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5146 - accuracy: 0.7599\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5111 - accuracy: 0.7608\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5054 - accuracy: 0.7750\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5005 - accuracy: 0.7976\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4895 - accuracy: 0.7660\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4968 - accuracy: 0.7738\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7518\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5536 - accuracy: 0.7689\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6212 - accuracy: 0.6750\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5304 - accuracy: 0.7703\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5777 - accuracy: 0.7412\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.7782\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5870 - accuracy: 0.7057\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5859 - accuracy: 0.7231\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.7436\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6318 - accuracy: 0.6526\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5604 - accuracy: 0.7163\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5912 - accuracy: 0.7008\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.7138\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6271 - accuracy: 0.6756\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6326 - accuracy: 0.6857\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.7819\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5994 - accuracy: 0.6660\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.7867\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5299 - accuracy: 0.7889\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.7714\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6036 - accuracy: 0.7065\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.8031\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7917\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5381 - accuracy: 0.7549\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6777 - accuracy: 0.6153\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.6308\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5468 - accuracy: 0.7431\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.7118 - accuracy: 0.5892\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5267 - accuracy: 0.7717\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5369 - accuracy: 0.7715\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7818\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6654 - accuracy: 0.6108\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.7825\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5565 - accuracy: 0.7329\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5320 - accuracy: 0.7822\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5444 - accuracy: 0.7499\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7885\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.7943\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7906\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.7907\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.7476\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5936 - accuracy: 0.6772\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.7857\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7825\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5903 - accuracy: 0.6946\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5633 - accuracy: 0.7310\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6257 - accuracy: 0.6872\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5960\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7447\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7990\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.7119\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.7882\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7915\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.6521\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.7494\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5483 - accuracy: 0.7682\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5854 - accuracy: 0.7296\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.7437\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.7864\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7735\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.7874\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6208\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.7942\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5447 - accuracy: 0.7513\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7314\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5248 - accuracy: 0.7862\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.6476\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7525\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6182 - accuracy: 0.6642\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5973 - accuracy: 0.6689\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5141 - accuracy: 0.7881\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5352 - accuracy: 0.7639\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7699\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5343 - accuracy: 0.7556\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5420 - accuracy: 0.7853\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6007 - accuracy: 0.7088\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7935\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.7554\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5075 - accuracy: 0.7964\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5295 - accuracy: 0.7825\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5303 - accuracy: 0.7875\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.7738\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5540 - accuracy: 0.7396\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.7296\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.7156\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5476 - accuracy: 0.7456\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5189 - accuracy: 0.7686\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5816 - accuracy: 0.6968\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5441 - accuracy: 0.7500\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7931\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5512 - accuracy: 0.7589\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5441 - accuracy: 0.7939\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7951\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.7817\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7619\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7353\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.7937\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.7943\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5168 - accuracy: 0.7797\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6561\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.7961\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.8021\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6061 - accuracy: 0.7060\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5439 - accuracy: 0.7817\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5777 - accuracy: 0.7161\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.7897\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.7824\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.7632 - accuracy: 0.5081\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.6092\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.7626\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5783 - accuracy: 0.7667\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6436 - accuracy: 0.6553\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5289 - accuracy: 0.7688\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5370 - accuracy: 0.7822\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.7476\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.7767\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5294 - accuracy: 0.7876\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5952 - accuracy: 0.6910\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.7068\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.7728\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5252 - accuracy: 0.7669\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5681\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6353 - accuracy: 0.6439\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5470 - accuracy: 0.7404\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7608\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5316 - accuracy: 0.7769\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.7907\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7776\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7861\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6131 - accuracy: 0.7029\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5911 - accuracy: 0.7253\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6165 - accuracy: 0.6883\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.7837\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5511 - accuracy: 0.7803\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5470 - accuracy: 0.7796\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5852 - accuracy: 0.7460\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.7754\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5500 - accuracy: 0.7786\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.7971\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.7844\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5248 - accuracy: 0.7758\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6185\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5872 - accuracy: 0.7192\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5949 - accuracy: 0.7110\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5547 - accuracy: 0.7697\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.7887\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.7628\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.7564\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5531 - accuracy: 0.7708\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7962\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5434 - accuracy: 0.7958\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5880 - accuracy: 0.7165\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5904 - accuracy: 0.7194\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5414 - accuracy: 0.7924\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5491 - accuracy: 0.7597\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5827 - accuracy: 0.7367\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7849\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5600 - accuracy: 0.7251\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.7961\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7957\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5327 - accuracy: 0.7904\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6115 - accuracy: 0.6399\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5413 - accuracy: 0.7862\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6375 - accuracy: 0.6726\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5492 - accuracy: 0.7685\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7588\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5320 - accuracy: 0.7769\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5859 - accuracy: 0.7610\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5400 - accuracy: 0.7690\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 0.7739\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5217 - accuracy: 0.7960\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.7960\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.7967\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5333 - accuracy: 0.7692\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5788 - accuracy: 0.7122\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.8306 - accuracy: 0.4421\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5755 - accuracy: 0.7271\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5445 - accuracy: 0.7572\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6029\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.7069\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.7925\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.7950\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5848 - accuracy: 0.7387\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.6146\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6036 - accuracy: 0.6857\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5770 - accuracy: 0.7332\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6247 - accuracy: 0.6949\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5497 - accuracy: 0.7668\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5755 - accuracy: 0.7631\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6153 - accuracy: 0.6737\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5468 - accuracy: 0.7757\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.7397\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.7139\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6630 - accuracy: 0.6489\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.5764\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5612 - accuracy: 0.7683\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.7504\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7715\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5879 - accuracy: 0.7175\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5524 - accuracy: 0.7708\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7485\n",
            "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4746 - accuracy: 0.7886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MjTir2g0xBU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76a75144-125c-499b-ef76-633aacf07ab6"
      },
      "source": [
        "print(best_param)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 5, 'nb_epoch': 10, 'optimizer': 'adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ar6PmTt00Go",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39952fa2-ff2c-4915-aa0c-b8687b02fcf2"
      },
      "source": [
        "print(best_acc)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8106250000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So5Jkhp61Ezc",
        "colab_type": "text"
      },
      "source": [
        "## Making best Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHjz0Kr-1JbJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "b8f71f16-5a49-4382-a7c7-9a284263067b"
      },
      "source": [
        "best_classifier = build_classifier(best_param['optimizer'])\n",
        "best_classifier.fit(X_train, y_train,\n",
        "                    batch_size=best_param['batch_size'],\n",
        "                    epochs=best_param['nb_epoch'])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1600/1600 [==============================] - 2s 1ms/step - loss: 0.5083 - accuracy: 0.7707\n",
            "Epoch 2/10\n",
            "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4025 - accuracy: 0.8259\n",
            "Epoch 3/10\n",
            "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3714 - accuracy: 0.8414\n",
            "Epoch 4/10\n",
            "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3628 - accuracy: 0.8491\n",
            "Epoch 5/10\n",
            "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3571 - accuracy: 0.8536\n",
            "Epoch 6/10\n",
            "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3529 - accuracy: 0.8554\n",
            "Epoch 7/10\n",
            "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3495 - accuracy: 0.8556\n",
            "Epoch 8/10\n",
            "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3459 - accuracy: 0.8575\n",
            "Epoch 9/10\n",
            "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3445 - accuracy: 0.8580\n",
            "Epoch 10/10\n",
            "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3431 - accuracy: 0.8583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f593d4fba20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecKgdtkW2NaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = best_classifier.predict(X_test) > 0.5"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKKptBKb2Yz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f5d8aa08-0cf1-434c-9bc9-02c4b00b1f7a"
      },
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1540,   55],\n",
              "       [ 212,  193]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6B07zUiT8-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ce1832a-22be-4436-fab6-5976c38fa4d2"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8665"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82Y-aB2wTq6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}